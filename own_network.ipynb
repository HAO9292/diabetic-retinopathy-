{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, BatchNormalization, merge, Conv2D\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, BatchNormalization, merge, Conv2D\n",
    "import keras.backend as K\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import add\n",
    "from keras.layers import Input,GlobalAveragePooling2D\n",
    "import keras\n",
    "from keras.models import  Model\n",
    "from keras.preprocessing.image import  ImageDataGenerator\n",
    "import keras.callbacks as kcallbacks\n",
    "import math\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_with_maxpool(input_img):\n",
    "    tower_1 = Conv2D(32, (1, 1), padding='same', activation='relu')(input_img)\n",
    "    tower_1=MaxPooling2D()(tower_1)\n",
    "    tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "    tower_1=MaxPooling2D()(tower_1)\n",
    "    tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "    tower_2=MaxPooling2D()(tower_2)\n",
    "    tower_2 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_2)\n",
    "    tower_2=MaxPooling2D()(tower_2)\n",
    "    tower_3 = Conv2D(128, (1, 1), padding='same', activation='relu')(input_img)\n",
    "    tower_3=MaxPooling2D()(tower_3)\n",
    "    tower_3 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_3)\n",
    "    tower_3=MaxPooling2D()(tower_3)\n",
    "    output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_img):\n",
    "    tower_1 = Conv2D(32, (1, 1), padding='same', activation='relu')(input_img)\n",
    "    tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "    tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "    tower_2 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_2)\n",
    "    tower_3 = Conv2D(128, (1, 1), padding='same', activation='relu')(input_img)\n",
    "    tower_3 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_3)\n",
    "    output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_img):\n",
    "    shortcut=input_img\n",
    "    x=conv_block(input_img)\n",
    "    x=add([shortcut,x])\n",
    "    x=Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(512, 512, 3))\n",
    "x=Conv2D(32,(3,3),padding='valid',activation='relu')(inputs)\n",
    "x=MaxPooling2D()(x)\n",
    "x=conv_block_with_maxpool(x)\n",
    "x=resnet(x)\n",
    "x=resnet(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x=Dense(128,activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(64,activation='relu')(x)\n",
    "x=Dropout(0.5)So the more even the test set is, the more objective the results are.(x)\n",
    "predictions=Dense(5,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Model(inputs=inputs,outputs=predictions)\n",
    "plot_model(model=model,to_file='./model.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 510, 510, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 255, 255, 32) 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 255, 255, 32) 1056        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 255, 255, 64) 2112        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 255, 255, 128 4224        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 127, 127, 32) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 127, 127, 64) 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 127, 127, 128 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 127, 127, 64) 18496       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 127, 127, 64) 36928       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 127, 127, 64) 73792       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 63, 63, 64)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 63, 63, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 63, 63, 64)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 63, 63, 192)  0           max_pooling2d_10[0][0]           \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 63, 63, 32)   6176        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 63, 63, 64)   12352       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 63, 63, 128)  24704       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 63, 63, 64)   18496       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 63, 63, 64)   36928       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 63, 63, 64)   73792       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 63, 63, 192)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 63, 63, 192)  0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 63, 63, 192)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 63, 63, 32)   6176        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 63, 63, 64)   12352       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 63, 63, 128)  24704       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 63, 63, 64)   18496       conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 63, 63, 64)   36928       conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 63, 63, 64)   73792       conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 63, 63, 192)  0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 63, 63, 192)  0           activation_3[0][0]               \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 63, 63, 192)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 192)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          24704       global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            325         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 515,685\n",
      "Trainable params: 515,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49658 images belonging to 5 classes.\n",
      "Found 10000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE=(512,512)\n",
    "INPUT_SIZE=(512,512,3)\n",
    "BATCHSIZE=16\n",
    "##################################\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './train/',\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        './test/',\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.3052 - acc: 0.4719Epoch 00001: val_loss improved from inf to 1.11939, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1391s 448ms/step - loss: 1.3051 - acc: 0.4719 - val_loss: 1.1194 - val_acc: 0.5367\n",
      "Epoch 2/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.1155 - acc: 0.5411Epoch 00002: val_loss improved from 1.11939 to 1.09283, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1392s 448ms/step - loss: 1.1155 - acc: 0.5411 - val_loss: 1.0928 - val_acc: 0.5427\n",
      "Epoch 3/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0942 - acc: 0.5452Epoch 00003: val_loss did not improve\n",
      "3104/3104 [==============================] - 1391s 448ms/step - loss: 1.0943 - acc: 0.5451 - val_loss: 1.0979 - val_acc: 0.5464\n",
      "Epoch 4/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0905 - acc: 0.5463Epoch 00004: val_loss improved from 1.09283 to 1.08210, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1391s 448ms/step - loss: 1.0905 - acc: 0.5463 - val_loss: 1.0821 - val_acc: 0.5457\n",
      "Epoch 5/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0859 - acc: 0.5467Epoch 00005: val_loss improved from 1.08210 to 1.08031, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1391s 448ms/step - loss: 1.0859 - acc: 0.5467 - val_loss: 1.0803 - val_acc: 0.5508\n",
      "Epoch 6/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0868 - acc: 0.5494Epoch 00006: val_loss did not improve\n",
      "3104/3104 [==============================] - 1391s 448ms/step - loss: 1.0868 - acc: 0.5494 - val_loss: 1.0819 - val_acc: 0.5468\n",
      "Epoch 7/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0810 - acc: 0.5497Epoch 00007: val_loss did not improve\n",
      "3104/3104 [==============================] - 1391s 448ms/step - loss: 1.0810 - acc: 0.5498 - val_loss: 1.0981 - val_acc: 0.5411\n",
      "Epoch 8/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0816 - acc: 0.5484Epoch 00008: val_loss improved from 1.08031 to 1.07650, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0816 - acc: 0.5483 - val_loss: 1.0765 - val_acc: 0.5512\n",
      "Epoch 9/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0799 - acc: 0.5500Epoch 00009: val_loss did not improve\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0800 - acc: 0.5500 - val_loss: 1.0942 - val_acc: 0.5487\n",
      "Epoch 10/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0785 - acc: 0.5482Epoch 00010: val_loss improved from 1.07650 to 1.07511, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0785 - acc: 0.5482 - val_loss: 1.0751 - val_acc: 0.5521\n",
      "Epoch 11/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0787 - acc: 0.5502Epoch 00011: val_loss improved from 1.07511 to 1.07050, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0787 - acc: 0.5502 - val_loss: 1.0705 - val_acc: 0.5515\n",
      "Epoch 12/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0774 - acc: 0.5512Epoch 00012: val_loss did not improve\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0773 - acc: 0.5513 - val_loss: 1.0739 - val_acc: 0.5532\n",
      "Epoch 13/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0763 - acc: 0.5491Epoch 00013: val_loss did not improve\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0764 - acc: 0.5491 - val_loss: 1.0793 - val_acc: 0.5532\n",
      "Epoch 14/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0757 - acc: 0.5506Epoch 00014: val_loss did not improve\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0757 - acc: 0.5506 - val_loss: 1.0767 - val_acc: 0.5556\n",
      "Epoch 15/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0730 - acc: 0.5536Epoch 00015: val_loss did not improve\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0730 - acc: 0.5535 - val_loss: 1.0789 - val_acc: 0.5532\n",
      "Epoch 16/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0732 - acc: 0.5541Epoch 00016: val_loss improved from 1.07050 to 1.06968, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0731 - acc: 0.5541 - val_loss: 1.0697 - val_acc: 0.5549\n",
      "Epoch 17/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0716 - acc: 0.5544Epoch 00017: val_loss improved from 1.06968 to 1.06671, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0717 - acc: 0.5543 - val_loss: 1.0667 - val_acc: 0.5591\n",
      "Epoch 18/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0700 - acc: 0.5566Epoch 00018: val_loss did not improve\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0700 - acc: 0.5566 - val_loss: 1.0733 - val_acc: 0.5508\n",
      "Epoch 19/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0713 - acc: 0.5550Epoch 00019: val_loss improved from 1.06671 to 1.06553, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0713 - acc: 0.5550 - val_loss: 1.0655 - val_acc: 0.5562\n",
      "Epoch 20/20\n",
      "3103/3104 [============================>.] - ETA: 0s - loss: 1.0680 - acc: 0.5550Epoch 00020: val_loss improved from 1.06553 to 1.06472, saving model to ./mymodel.h5\n",
      "3104/3104 [==============================] - 1390s 448ms/step - loss: 1.0680 - acc: 0.5550 - val_loss: 1.0647 - val_acc: 0.5588\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "savepath='./mymodel.h5'\n",
    "epochs=20\n",
    "#定义一下优化的方法\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#compile一下模型\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "#train model\n",
    "earlyStopping=kcallbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1, mode='auto')\n",
    "saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "#     model_vgg19_clair.fit(X_train_vgg,y_train,batch_size=batchsize,epochs=epochs,verbose=1,\n",
    "#               validation_data=(X_test_vgg,y_test),shuffle=True,callbacks=[earlyStopping,saveBestModel])\n",
    "hist=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=math.ceil(49658/BATCHSIZE),\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=math.ceil(10000/BATCHSIZE),\n",
    "    callbacks=[earlyStopping,saveBestModel],\n",
    "    workers=8\n",
    ")\n",
    "with open('mymodel_log.txt','w') as f:\n",
    "    f.write(str(hist.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
